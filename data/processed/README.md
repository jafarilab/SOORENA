# Data/Processed Directory

This directory contains all processed datasets used for training, validation, testing, and prediction.

## File Overview

| File | Size | Papers | Description | Generated By |
|------|------|--------|-------------|--------------|
| **Core Dataset** |
| `modeling_dataset.csv` | 331M | 254,212 | **MASTER dataset** - All papers (labeled + unlabeled) after cleaning and filtering | `prepare_data.py` |
| | | | | |
| **Labeled Data (Ground Truth)** |
| `train.csv` | 1.3M | 932 | Labeled papers with mechanisms (70% split) | `prepare_data.py` |
| `val.csv` | 285K | 200 | Labeled papers with mechanisms (15% split) | `prepare_data.py` |
| `test.csv` | 283K | 200 | Labeled papers with mechanisms (15% split) | `prepare_data.py` |
| | | | | |
| **Stage 1 Training Data (Binary Classification)** |
| `stage1_unlabeled_negatives.csv` | 3.5M | 2,664 | Unlabeled papers sampled as **negative examples** during Stage 1 training (2:1 ratio) | `train_stage1.py` |
| `stage1_unlabeled_unused.csv` | 326M | 250,216 | Unlabeled papers **NOT used** in training - for prediction only | `train_stage1.py` |
| | | | | |
| **Evaluation Results** |
| `stage1_test_eval.csv` | 820K | 600 | Stage 1 binary classifier test results (200 positive + 400 negative) | `evaluate.py` |
| `stage2_test_eval.csv` | 284K | 200 | Stage 2 multiclass classifier test results | `evaluate.py` |

---

## Data Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prepare_data.py          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚ Raw data cleaning      â”‚
â”‚ â”‚ Term normalization     â”‚
â”‚ â”‚ Filter rare terms      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚
â”‚             â–¼
â”œâ”€â”€â”€â”€â”€> modeling_dataset.csv (254,212 papers)
â”‚             â”‚
â”‚             â”œâ”€> 1,332 labeled (has mechanism)
â”‚             â”‚   â”œâ”€> train.csv (932)
â”‚             â”‚   â”œâ”€> val.csv (200)
â”‚             â”‚   â””â”€> test.csv (200)
â”‚             â”‚
â”‚             â””â”€> 252,880 unlabeled (no mechanism)
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ train_stage1.py          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚ Sample 2:1 ratio       â”‚
â”‚ â”‚ (2 negative : 1 pos)   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚
â”‚             â”œâ”€> stage1_unlabeled_negatives.csv (2,664)
â”‚             â”‚   Used as negative samples during training
â”‚             â”‚
â”‚             â””â”€> stage1_unlabeled_unused.csv (250,216)
â”‚                 Never seen by model - for prediction
â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Important Notes

### ğŸ¯ For Reproducibility

**All sampling uses `RANDOM_SEED=42`** - This ensures:
- The exact same papers are selected every time
- Training is reproducible
- Results can be verified by others

### ğŸ“Š Stage 1 Sampling Strategy

Stage 1 trains a **binary classifier** (has mechanism vs. no mechanism):

- **Positive examples**: 1,332 labeled papers (known mechanisms)
- **Negative examples**: 2,664 unlabeled papers (sampled at 2:1 ratio)
- **Total training data**: 3,996 papers (1,332 + 2,664)

The 2:1 ratio balances the classes while maintaining enough positive examples.

### ğŸ” Which Files to Use?

**For Training:**
- âœ… Use `train.csv`, `val.csv`, `test.csv`
- âœ… Use `stage1_unlabeled_negatives.csv` (generated during `train_stage1.py`)

**For Prediction:**
- âœ… Use `stage1_unlabeled_unused.csv` - These papers were NEVER seen during training
- âŒ Don't predict on `stage1_unlabeled_negatives.csv` - Already used in training (data leakage!)

**For Analysis:**
- âœ… Use `modeling_dataset.csv` - Complete overview of all available data
- âœ… Use evaluation CSVs - Check model performance

### ğŸ—‘ï¸ Can I Delete Any Files?

**Keep These:**
- `modeling_dataset.csv` - Master source
- `train.csv`, `val.csv`, `test.csv` - Ground truth
- `stage1_unlabeled_negatives.csv` - Documents training negatives
- `stage1_unlabeled_unused.csv` - For predictions

**Optional (can regenerate):**
- `stage1_test_eval.csv` - Run `evaluate.py` to recreate
- `stage2_test_eval.csv` - Run `evaluate.py` to recreate

---

## File Relationships

```
modeling_dataset.csv (254,212 total)
â”‚
â”œâ”€ Labeled (1,332)
â”‚  â”œâ”€ train.csv (932)
â”‚  â”œâ”€ val.csv (200)
â”‚  â””â”€ test.csv (200)
â”‚
â””â”€ Unlabeled (252,880)
   â”œâ”€ stage1_unlabeled_negatives.csv (2,664) â† Used in training
   â””â”€ stage1_unlabeled_unused.csv (250,216) â† For prediction
```

---

## Column Descriptions

### Core Columns (all files)
- `PMID`: PubMed ID (unique identifier)
- `text`: Combined title + abstract (cleaned)
- `Terms`: Autoregulatory mechanism types (comma-separated)
- `has_mechanism`: Boolean - paper has autoregulatory mechanism

### Additional Columns

**In labeled files (train/val/test):**
- `label`: Primary mechanism type (for stratified splitting)

**In Stage 1 files:**
- `split`: Which split the paper belongs to (train/val/test)

**In evaluation files:**
- `predicted`: Model prediction
- `actual`: Ground truth label
- `confidence`: Prediction confidence score

---

## Quick Reference

### Regenerate These Files

```bash
# Regenerate master dataset and splits
python scripts/python/data_processing/prepare_data.py

# Regenerate Stage 1 sampled datasets (during training)
python scripts/python/training/train_stage1.py

# Regenerate evaluation results
python scripts/python/training/evaluate.py
```

### Check File Sizes

```bash
ls -lh data/processed/
wc -l data/processed/*.csv
```

---

## Questions?

- **"Why so many unlabeled papers?"** - We have 252K unlabeled papers but only used 2,664 for training. The rest (~250K) are for testing model predictions on truly unseen data.

- **"Can I retrain with different ratios?"** - Yes! Change the sampling in `train_stage1.py` (line 32-36), but remember to update `RANDOM_SEED` for reproducibility.

- **"Where are the 3M new predictions?"** - Those are in `data/pred/` (input) and `results/` (output), not in this directory.
