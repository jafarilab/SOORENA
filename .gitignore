# Ignore OS files
.DS_Store
**/.DS_Store
__pycache__/
**/__pycache__/
*.pyc
.ipynb_checkpoints/

# Ignore IDE files
.vscode/
.idea/
*.swp
*.swo
*~

# Ignore temporary files
*.tmp
*.bak
*.log

# Ignore secrets/keys
*.key
*.pem
*.p12
*.pfx
*.pub
.env
.env.*

# Ignore only raw scratch data
data/raw/

# Allow all processed data to be tracked by LFS
!data/**
!shiny_app/data/**

# Generated processed datasets (rebuild via prepare_data.py)
data/processed/modeling_dataset.csv
data/processed/train.csv
data/processed/val.csv
data/processed/test.csv
data/processed/stage1_test_eval.csv
data/processed/stage2_test_eval.csv

# Local enrichment outputs and caches
.cache/
pubtator_genes*.csv
shiny_app/data/predictions_for_app_backup.csv
shiny_app/data/predictions_for_app_sample_10.csv
data/protein_cache.json

# Ignore large model binaries unless needed
# (Tracked in Git LFS when required)
# models/*.pt
data/pred/*.tsv

# Ignore large prediction files (>2GB - exceeds GitHub LFS limit)
# These can be regenerated by running the prediction pipeline
results/new_predictions.csv
shiny_app/data/predictions_for_app.csv
shiny_app/data/predictions_for_app_enriched.csv
results/*_checkpoint.csv


# Generated predictions and merges
results/*.csv
**/*_enriched*.csv
**/*_merged*.csv

# App data (generated)
shiny_app/data/*.csv


# Local notebooks
N.ipynb
